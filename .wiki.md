# Project Summary
The AI Mentor project is a local-first AI application designed to enhance productivity and knowledge retention for Windows 11 users. It offers personalized assistance through an interactive chat interface, utilizing Ollama for AI capabilities and integrating with the ChatGPT API for online support. A notable feature is the sports betting analytics dashboard, providing users with insights and performance tracking for their betting predictions. The application operates offline while allowing access to supplementary online resources, positioning itself as an essential tool for learning and productivity.

# Project Module Description
The project consists of a backend built with FastAPI and a frontend developed using React. Key modules include:
- **Backend**: Manages conversations, memories, and knowledge with a modular structure. It includes services for performance metrics, streaming capabilities, and the latest features for sports betting predictions.
- **Frontend**: Provides an intuitive interface with components for chat, memory management, knowledge base access, and an analytics dashboard that supports real-time streaming responses.

# Directory Tree
```
AI Mentor
├── start_windows_hidden.vbs                # Hidden launcher for background execution
├── start_windows.bat                        # Visible launcher (for debugging)
├── backend/                                 # FastAPI Backend
│   ├── main.py                              # API entry point with data source management
│   ├── database.py                          # Database manager (SQLite)
│   ├── models.py                            # SQLAlchemy models
│   ├── analytics_models.py                  # Models for analytics and predictions
│   ├── data_sources_service.py              # Service for managing online data sources
│   ├── migrate_sources.py                   # Migration script for data sources table
│   ├── seed_sources.py                      # Seed data for default sources
│   ├── ai_service.py                        # Ollama integration and performance optimizations
│   ├── prediction_analysis_service.py       # Prediction analysis logic with online/offline separation
├── app/frontend/                           # React Frontend
│   ├── src/
│   │   ├── components/                     # UI components including settings and analytics
│   │   ├── hooks/                          # Custom hooks
│   │   ├── services/                       # API client
│   │   └── types/                          # TypeScript types
│   └── vite.config.ts                      # Vite configuration
├── README.md                               # Documentation for project overview, installation, and usage instructions
├── SELF_TEST_REPORT.md                     # Report on the self-test and system verification
└── PREDICTION_LOGIC_REPORT.md              # Report on the prediction analysis logic
```

# File Description Inventory
- **start_windows_hidden.vbs**: Script to start the application without showing console windows.
- **start_windows.bat**: Script to start the application stack with visible console windows (for debugging).
- **backend/**: Contains all backend-related files, including API and database management, with performance enhancements and memory command handling improvements.
- **app/frontend/**: Contains the frontend codebase, including components, hooks, services, and configuration.
- **README.md**: Documentation for project overview, installation, and usage instructions.
- **SELF_TEST_REPORT.md**: Detailed report on the implementation and verification of the system's functionality.
- **PREDICTION_LOGIC_REPORT.md**: Detailed report on the implementation of the prediction analysis features and logic.
- **.env.example**: Template for configuring environment variables with performance settings.

# Technology Stack
- **Frontend**: Vite, React, TypeScript, Tailwind CSS, shadcn/ui
- **Backend**: FastAPI, SQLAlchemy, SQLite
- **AI**: Ollama (llama3:latest)
- **Online Features**: ChatGPT API for online assistance

# Usage
### Installation
1. **Ollama**: Download and run the following command:
   ```bash
   ollama pull llama3:8b
   ```
2. **Python 3.10+**: Install from the official Python website.
3. **Node.js 20+**: Install from the official Node.js website.
4. **pnpm**: Install globally using:
   ```bash
   npm install -g pnpm
   ```

### Setup Dependencies
#### Backend
```bash
cd backend
pip install -r requirements.txt
```

#### Frontend
```bash
cd app/frontend
pnpm install
```

### Running the Application
- For normal use (recommended), double-click:
   ```bash
   start_windows_hidden.vbs
   ```

- For debugging, double-click:
   ```bash
   start_windows.bat
   ```

### Stopping the Application
To stop the application, close the browser window or use Task Manager to end the backend and frontend processes.

### Database Migration
Run the migration script to create new analytics tables:
```bash
cd backend
python migrate_sources.py
```

### Seed Test Data
(Optional) Seed the database with test data:
```bash
cd backend
python seed_sources.py
```

### Accessing Analytics
1. Launch the application.
2. Click on the Analytics button in the sidebar to access the analytics dashboard.

### API Usage
1. **Set API Key**:
   ```bash
   curl -X POST /api/v1/predictions/set-api-key -d '{"api_key": "YOUR_API_KEY"}'
   ```
2. **Check Data Status**:
   ```bash
   curl /api/v1/predictions/data-status
   ```
3. **Analyze and Predict**:
   ```bash
   curl -X POST /api/v1/predictions/analyze -d '{"home_team": "Team A", "away_team": "Team B"}'
   ```
