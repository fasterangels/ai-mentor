# AI Mentor - Personal AI Assistant

An intelligent AI assistant with memory and knowledge management capabilities, powered by Ollama and built with FastAPI + React.

---

## Release v0.2.0 (Windows desktop)

**Install (Windows):**

1. Open the [Releases](https://github.com/fasterangels/ai-mentor/releases) page and download **AI-Mentor-Windows-setup.exe** for v0.2.0.
2. Run the installer (per-user, no admin required). The app and backend run via a Scheduled Task (`AI_Mentor_Backend`).
3. Launch **AI ÎœÎ­Î½Ï„Î¿ÏÎ±Ï‚** from the Start Menu or desktop shortcut.

**Known limitations:**

- Windows only (NSIS installer).
- Backend must be running (started by installer/task); if the app shows "Backend startingâ€¦", wait a few seconds or restart the app.
- First analysis may take longer while the backend warms up.

---

## ğŸš€ Quick Start

### **For Normal Use (Recommended)**

**Double-click:** `start_windows_hidden.vbs`

- âœ… Starts the application in the background
- âœ… No visible console windows
- âœ… Browser opens automatically
- âœ… Clean user experience

### **For Debugging**

**Double-click:** `start_windows.bat`

- âœ… Shows console windows for backend and frontend
- âœ… Displays startup logs and errors
- âœ… Useful for troubleshooting

---

## ğŸ“‹ Prerequisites

Before running AI Mentor, ensure you have:

1. **Ollama** installed and running
   - Download: https://ollama.ai
   - Verify: Run `ollama list` in terminal

2. **Python 3.8+** installed
   - Download: https://www.python.org/downloads/

3. **Node.js 16+** and **pnpm** installed
   - Node.js: https://nodejs.org/
   - pnpm: `npm install -g pnpm`

4. **Required Python packages** (auto-installed on first run)
   - FastAPI, Uvicorn, SQLAlchemy, etc.

---

## ğŸ¯ Features

### Core Capabilities
- **AI Chat Interface** - Conversational AI powered by Ollama
- **Memory System** - Remembers important information with importance scoring
- **Knowledge Base** - Store and retrieve structured knowledge
- **Context-Aware** - Uses memories and knowledge to provide relevant responses
- **Conversation Management** - Organize chats into separate conversations

### Performance Optimizations (Version 7)
- **Streaming Responses** - See AI responses as they're generated
- **Fast Model** - Uses llama3:8b for 2x faster responses
- **Context Trimming** - Optimized context size (60% reduction)
- **Model Warm-up** - Eliminates cold start delay
- **Performance Metrics** - Real-time latency and tokens/sec tracking

### Data Safety
- **External Data Folder** - All data stored in `%USERPROFILE%\AI_Mentor_Data`
- **Automatic Migration** - Seamlessly migrates from old database location
- **Backup-Friendly** - Single folder contains all user data

---

## ğŸ–¥ï¸ System Requirements

- **OS:** Windows 11 (or Windows 10)
- **RAM:** 8GB minimum (16GB recommended for larger models)
- **Disk:** 10GB free space (for Ollama models)
- **Network:** Internet connection for initial setup

---

## ğŸ“‚ Project Structure

```
AI_Mentor/
â”œâ”€â”€ start_windows_hidden.vbs    # Hidden launcher (recommended)
â”œâ”€â”€ start_windows.bat            # Visible launcher (debugging)
â”œâ”€â”€ backend/                     # FastAPI backend
â”‚   â”œâ”€â”€ main.py                 # API endpoints
â”‚   â”œâ”€â”€ ai_service.py           # Ollama integration
â”‚   â”œâ”€â”€ database.py             # Database management
â”‚   â”œâ”€â”€ models.py               # Data models
â”‚   â””â”€â”€ *_service.py            # Business logic
â”œâ”€â”€ app/frontend/               # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # UI components
â”‚   â”‚   â””â”€â”€ services/           # API client
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md                   # This file
```

---

## ğŸ”§ Configuration (Optional)

Create `backend/.env` file for custom settings:

```bash
# Model Configuration
OLLAMA_MODEL=llama3:8b          # Default model (fast)
OLLAMA_URL=http://localhost:11434

# Performance Tuning
STREAMING_ENABLED=true          # Enable streaming responses
MAX_OUTPUT_TOKENS=512           # Max tokens per response
TEMPERATURE=0.7                 # Response randomness (0-1)
TOP_P=0.9                       # Nucleus sampling threshold

# Data Directory (optional override)
# DATA_DIR=D:\MyCustomPath\AI_Mentor_Data

# OpenAI API Key (optional, for online mode)
# OPENAI_API_KEY=your-api-key-here
```

---

## ğŸ“Š Performance Metrics

Access real-time performance data:
- **Metrics API:** http://localhost:8000/api/v1/ai/metrics
- **Health Check:** http://localhost:8000/health

**Expected Performance:**
- First message: ~1-2s (with warm-up)
- Subsequent messages: ~1-2s
- Context size: 60% smaller than previous versions
- Streaming: Immediate token display

---

## ğŸ—‚ï¸ Data Folder & Backups

### Data Location
All user data is stored in: `%USERPROFILE%\AI_Mentor_Data\`

**Contents:**
- `ai_mentor.db` - SQLite database with all conversations, memories, and knowledge

### Backup Strategy
**To backup your data:**
1. Close AI Mentor application
2. Copy the entire `AI_Mentor_Data` folder
3. Store in a safe location (external drive, cloud storage, etc.)

**To restore from backup:**
1. Close AI Mentor application
2. Replace `%USERPROFILE%\AI_Mentor_Data\` with your backup folder
3. Restart AI Mentor

### Moving Data to Another Computer
1. Copy `AI_Mentor_Data` folder from old computer
2. On new computer, place it in `%USERPROFILE%\AI_Mentor_Data\`
3. Install AI Mentor and run normally

---

## ğŸ› ï¸ Troubleshooting

### Application Won't Start

**Check Ollama:**
```bash
ollama list
```
If not running: `ollama serve`

**Check Python:**
```bash
python --version
```
Should be 3.8 or higher

**Check Node.js:**
```bash
node --version
pnpm --version
```

### Console Windows Appear (When Using Hidden Launcher)

If you see console windows when using `start_windows_hidden.vbs`:
1. Right-click the file â†’ Properties
2. Ensure it opens with "Microsoft Windows Based Script Host"
3. Try running as Administrator

**Alternative:** Use PowerShell hidden launcher:
```powershell
Start-Process -FilePath "start_windows.bat" -WindowStyle Hidden
```

### Slow Responses

**Install faster model:**
```bash
ollama pull llama3:8b
```

**Check metrics:**
- Open http://localhost:8000/api/v1/ai/metrics
- Verify `model: llama3:8b` and `streaming_enabled: true`

### Database Issues

**Reset database (WARNING: Deletes all data):**
1. Close AI Mentor
2. Delete `%USERPROFILE%\AI_Mentor_Data\ai_mentor.db`
3. Restart AI Mentor (new database will be created)

**Backup first!**

### Port Already in Use

If ports 8000 or 3000 are busy:
1. Close other applications using these ports
2. Or modify ports in:
   - Backend: `backend/main.py` (line: `uvicorn.run(..., port=8000)`)
   - Frontend: `app/frontend/vite.config.ts`

---

## ğŸ” API Documentation

Once running, access interactive API docs:
- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

**Key Endpoints:**
- `GET /health` - System health check
- `GET /api/v1/ai/status` - Ollama connection status
- `GET /api/v1/ai/metrics` - Performance metrics
- `POST /messages` - Send message (non-streaming)
- `POST /messages/stream` - Send message (streaming)
- `GET /conversations` - List conversations
- `GET /memories` - List memories
- `GET /knowledge` - List knowledge entries

---

## ğŸ“š Additional Resources

### Documentation
- **Performance Pack Report:** `PERFORMANCE_PACK_REPORT.md`
- **Validation Report:** `FINAL_VALIDATION_REPORT.md`
- **Data Folder Guide:** `DATA_FOLDER_MIGRATION_GUIDE.md`

### Support
- **Ollama Documentation:** https://ollama.ai/docs
- **FastAPI Documentation:** https://fastapi.tiangolo.com/
- **React Documentation:** https://react.dev/

---

## ğŸ‰ Version History

### Version 7 - Performance Pack (Current)
- âœ… Streaming responses (SSE)
- âœ… llama3:8b default model (2x faster)
- âœ… Context trimming (60% reduction)
- âœ… Model warm-up on startup
- âœ… Performance metrics API
- âœ… Hidden launcher for clean UX

### Version 6 - Data Folder Architecture
- âœ… External data folder (`AI_Mentor_Data`)
- âœ… Automatic database migration
- âœ… Backup-friendly structure

### Earlier Versions
- Basic chat functionality
- Memory and knowledge systems
- Conversation management

---

## ğŸ“ License

This project is for personal use. Modify and distribute as needed.

---

## ğŸ¤ Contributing

Contributions welcome! Feel free to:
- Report bugs
- Suggest features
- Submit pull requests

---

**Enjoy your AI Mentor! ğŸš€**

For questions or issues, check the troubleshooting section above or review the validation reports in the project folder.